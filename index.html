<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Metadata of the Webpage -->
    <!-- Character-set Metadata -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <!-- Viewport Metadata -->
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- Description Metadata-->
    <meta name="description" content="Portfolio Website" />
    <!-- Author Metadata -->
    <meta name="author" content="Shivani Gawande" />
    <!-- Keyword Metadata -->
    <meta
      name="keywords"
      content="Shivani Gawande,Shivani, Shivani NYU, SHivani Gawande NYU, Shivani Govardhan Gawande, Shivani Govardhan Gawande Citi, Shivani Gawande Citi, Shivani Gawande NYU, Shivani Gawande Cummins, Shivani Gawande IBM, Shivani, Shivani Gawande Meted, Shivani Gawande CITI"
    />
    <!-- Webpage Logo -->
    <link rel="shortcut icon" href="./assets/img/favicon.ico" />
    <!-- Webpage Title -->
    <title>Shivani Gawande</title>

    <!-- Import CSS: Main Stylesheet -->
    <link rel="stylesheet" href="./assets/css/main.css" />
  </head>

  <body>
    <div id="particles-js">
      <div class="header">
        <picture>
          <source
            type="image/webp"
            srcset="./assets/img/favicon.ico"
            alt="Professional Me"
            width="20%"
            style="border-radius: 50%"
          />
          <img
            src="./assets/img/jpg/Professional-Picture-Me.jpg"
            alt="Professional Me"
            width="20%"
            style="border-radius: 50%"
          />
        </picture>
        <p>
         
        </p>
         <h3>
          <span class="site-title">Shivani Gawande</span>
          <span class="site-description"> • Programmer • Big Data Analyst • NLP enthusiast </span>
        </h3>
        <div class="header-icons">
          <a aria-label="My LinkedIn Profile" target="_blank" href="https://www.linkedin.com/in/shivanigawande/">
            <i class="icon fa fa-linkedin" aria-hidden="true"></i>
          </a>
          <a aria-label="My Github Profile" target="_blank" href="https://github.com/ShivaniGawande">
            <i class="icon fa fa-github-alt" aria-hidden="true"></i>
          </a>
          <a aria-label="My Résumé" target="_blank" href="https://drive.google.com/file/d/1RsyTvXdbtPYqRgUIfmipplxpJ-yr9SiT">
            <i class="icon fa fa fa-file-pdf-o" aria-hidden="true" ></i>
          </a>
          <a aria-label="Send Email" href="mailto:sg6630@nyu.edu" target="_blank"
            ><i class="icon fa fa-envelope"></i
          ></a>
        </div>
        <div class="header-links">
          <a class="link" href="#about" data-scroll>About Me</a>
          <a class="link" href="#projects" data-scroll>Projects</a>
        </div>
      </div>
      <a class="down" href="#about" data-scroll><i class="icon fa fa-chevron-down" aria-hidden="true"></i></a>
    </div>

    <!-- About Section -->
    <section id="about">
      <!-- User Introduction-->
      <div class="user-details">
        <h1>My Story</h1>
        <p>
          <p>
          Hey there! I'm Shivani, a grad student at NYU, diving deep into the world of Computer Engineering. My passion for Data Science has led me through exciting courses like Probability, Programming for Data Science, Machine Learning, Deep Learning, and Natural Language Understanding. These experiences have given me a solid foundation in the math and algorithms behind Data Science.

          </p>
        <p></p>Currently, I'm a Graduate Research Assistant, working with  <a class="link" href="https://www.notaphonologist.com/"> Professor Yiding Hao</a> on making Large Language Models more interpretable using innovative techniques like Boundless Distributed Alignment Search. This past summer, I interned at Meted LLC, an edtech startup, where I helped build a personal tutor API using PyTorch, GPT-3, LangChain, Flask, and VectorDB.

      </p>
        <p></p>Before my grad studies, I spent 3.5 years as a Senior Analyst at Citibank, where I optimized real-time trade processing across different assets using Spark, Kafka, and Gemfire. I also collaborated with the Data and Regulatory team to develop critical report-generation tools.
        Working in fintech exposed me to handling critical, sensitive data and implementing efficient solutions within constrained environments.
        </p>
      </div>
      </div>
    </section>

    <!-- Projects Section -->
    <section id="projects">
      <div class="user-details">
        <h1>Featured Projects</h1>
      </div>

      <!-- User Project #1: Personal Résumé Website -->
      <div class="user-projects">
        <div class="images-right">
          <picture>
            <source type="image/webp" srcset="./assets/img/webp/Credit Risk Assessment using Causal Inference.webp" alt="Credit Risk Assessment using Causal Inference" />
            <img alt="Credit Risk Assessment using Causal Inference" src="./assets/img/jpg/Credit-Risk-Assessment-using-Causal-Inference.jpg" />
          </picture>
        </div>
        <div class="contents" style="text-align: center">
          <h3>Credit Risk Assessment using Causal Inference</h3>
          <div>
            <img
              height="32"
              width="32"
              src="https://unpkg.com/simple-icons@3.4.0/icons/pytorch.svg"
              style="filter: invert(73%) sepia(74%) saturate(1552%) hue-rotate(169deg) brightness(109%) contrast(97%)"
            />
            &nbsp;
            <img
              height="32"
              width="32"
              src="https://unpkg.com/simple-icons@3.4.0/icons/python.svg"
              style="filter: invert(24%) sepia(14%) saturate(2270%) hue-rotate(222deg) brightness(102%) contrast(90%)"
            />
            &nbsp;
            <img height="32" width="32" src="https://unpkg.com/simple-icons@3.4.0/icons/github.svg" />
          </div>
          <p style="text-align: justify">
           <p></p>Performed Exploratory Data Analysis for hypothesis testing and achieved an accuracy of ~95% using CatBoost Regression based on 50.68 GB anonymized and normalized data in Parquet provided by AMEX.
        </p><p></p>Implemented a causal inference model to assess credit card applicants' credit risk, used a custom ML wrapper to encapsulate the algorithm, and passed it to the MLOps pipeline to facilitate deployment and monitoring.
          </p>
          <a class="project-link" target="_blank" href="">Check it out!</a>
        </div>
      </div>

      <!-- User Project #2: Enhanced Multitask Learning Approach for Question Answering using NER as Auxiliary Tasks -->
      <div class="user-projects">
        <div class="images-left">
          <picture>
            <source type="image/webp" srcset="./assets/img/webp/MTL.webp" alt="MTL" />
            <img alt="MTL" src="./assets/img/jpg/MTL.jpg" />
          </picture>
        </div>
        <div class="contents-right" style="text-align: center">
          <h3>Enhanced Multitask Learning Approach for Question Answering using NER as Auxiliary Tasks</h3>
          <img
              height="32"
              width="32"
              src="https://unpkg.com/simple-icons@3.4.0/icons/pytorch.svg"
              style="filter: invert(73%) sepia(74%) saturate(1552%) hue-rotate(169deg) brightness(109%) contrast(97%)"
            />
            &nbsp;
            <img
              height="32"
              width="32"
              src="https://unpkg.com/simple-icons@3.4.0/icons/python.svg"
              style="filter: invert(24%) sepia(14%) saturate(2270%) hue-rotate(222deg) brightness(102%) contrast(90%)"
            />
          &nbsp;
          <img height="32" width="32" src="https://unpkg.com/simple-icons@3.4.0/icons/github.svg" />
          <p style="text-align: justify">
           <p>Engineered and deployed a novel multi-task learning approach that uses a pre-trained Language Model to simultaneously fine-tune Named Entity Recognition and domain-specific Question-Answering tasks in mini-batches.
</p><p>Achieved 0.925 F1-score on SQUAD dataset and 0.828 F1-score on NewsQA demonstrating increased performance compared to the single-task BERT model
          </p>
          <a class="project-link" target="_blank" href="https://github.com/ShivaniGawande/ETL-Pipeline-for-SEC-financial-data"
            >Check it out!</a
          >
        </div>
      </div>

      <!-- User Project #3: Generating “Silver” labels for unlabelled data using LLMs with Neural relation and Explanation classifiers -->
      <div class="user-projects">
        <div class="images-right">
          <picture>
            <source type="image/webp" srcset="./assets/img/webp/Silver-labels.webp" alt="Silver Labels" />
            <img alt="Silver Labels" src="./assets/img/jpg/Silver Labels.jpg" />
          </picture>
        </div>
        <div class="contents" style="text-align: center">
          <h3>Generating “Silver” labels for unlabelled data using LLMs with Neural relation and Explanation classifiers</h3>
          <p style="text-align: justify">
           <p>Performed a successful assessment of GPT models in tandem with bootstrapping Neural Relation and Explanation Classifiers to infer rules from labeled data in low-resourced settings.
</p><p>Improved the accuracy for predicting correct labels for unlabelled data by 15% compared to the SOTA model for the TACRED relation extraction dataset.
          </p>
          <a class="project-link" target="_blank" href="">
            Check it out!
          </a>
        </div>
      </div>

      <!-- Use Project #4: Valuto: ETL Pipeline for Financial Data from US Securities and Exchange Commission 	 -->
      <div class="user-projects">
        <div class="images-left">
          <picture>
            <source
              type="image/webp"
              srcset="./assets/img/webp/ETL-pipeline.webp"
              alt="Valuto: Account Management System"
            />
            <img alt="Valuto: Account Management System" src="./assets/img/jpg/ETL-pipeline.jpg" />
          </picture>
        </div>
        <div class="contents-right" style="text-align: center">
          <h3>ETL Pipeline for Financial Data from US Securities and Exchange Commission </h3>
          <p style="text-align: justify">
            <p>Implemented a Python-based pipeline to efficiently process and integrate financial data from diverse sources, including CSV files and RESTful APIs, obtained from the US Securities and Exchange Commission (SEC).
</p><p>Utilized SQL to perform data extraction and transformation, ensuring data quality and consistency, and created an interactive dashboard using Tableau for data visualization. 
          </p>
          <a class="project-link" target="_blank" href="https://github.com/ShivaniGawande/DLFinalProject_Fall22/blob/main/BERT_on_mergedData.ipynb">
            Check it out!
          </a>
        </div>
      </div>
    </section>

    <footer class="footer">
      <p>&copy; Shivani Gawande, 2023</p>
    </footer>

    <!-- Import JS: Particles Theme -->
    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <!-- Import JS: Sweet Scroll -->
    <script src="./assets/js/sweet-scroll.min.js"></script>
    <!-- Import JS: Google Analytics -->
    <script src="./assets/js/google-analytics.js"></script>
    <!-- Import JS: Main Script -->
    <script src="./assets/js/main.js"></script>
  </body>
</html>
